{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization Aware Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from model import resnet20\n",
    "from sparsebit.quantization import QuantModel, parse_qconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Preparation\n",
    "## 1.0 Check your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    raise NotImplementedError(\"This example should run on a GPU device.\")    #确定在GPU上运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"qconfig.yaml\"    #QAT配置文件——包括量化方式（dorefa/lsq），权重和激活值的量化bit数等\n",
    "workers =4\n",
    "epochs = 200\n",
    "start_epoch = 0\n",
    "batch_size = 128\n",
    "lr =0.1\n",
    "momentum = 0.9\n",
    "weight_decay =1e-4\n",
    "print_freq = 10\n",
    "pretrained=\"\"\n",
    "qconfig = parse_qconfig(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Import the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet20(num_classes=10)    #以resnet20作为基础模型\n",
    "if pretrained:    #可以采用pretrained中保存的模型参数\n",
    "    ckpt_state_dict = torch.load(pretrained)\n",
    "    model.load_state_dict(ckpt_state_dict)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Load CIFAR10 trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),    #随机水平翻转\n",
    "        transforms.RandomCrop(32, 4),    #随机裁剪\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),    #指定各通道均值和标准差，将数据归一化\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "testset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Turn the model into QuantModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name                   target                   args                                   kwargs\n",
      "-------------  ---------------------  -----------------------  -------------------------------------  --------\n",
      "placeholder    x                      x                        ()                                     {}\n",
      "call_module    conv1                  conv1                    (x,)                                   {}\n",
      "call_module    bn1                    bn1                      (conv1,)                               {}\n",
      "call_module    relu                   relu                     (bn1,)                                 {}\n",
      "call_module    layer1_0_conv1         layer1.0.conv1           (relu,)                                {}\n",
      "call_module    layer1_0_bn1           layer1.0.bn1             (layer1_0_conv1,)                      {}\n",
      "call_module    layer1_0_relu          layer1.0.relu            (layer1_0_bn1,)                        {}\n",
      "call_module    layer1_0_conv2         layer1.0.conv2           (layer1_0_relu,)                       {}\n",
      "call_module    layer1_0_bn2           layer1.0.bn2             (layer1_0_conv2,)                      {}\n",
      "call_function  add                    <built-in function add>  (layer1_0_bn2, relu)                   {}\n",
      "call_module    layer1_0_relu_1        layer1.0.relu            (add,)                                 {}\n",
      "call_module    layer1_1_conv1         layer1.1.conv1           (layer1_0_relu_1,)                     {}\n",
      "call_module    layer1_1_bn1           layer1.1.bn1             (layer1_1_conv1,)                      {}\n",
      "call_module    layer1_1_relu          layer1.1.relu            (layer1_1_bn1,)                        {}\n",
      "call_module    layer1_1_conv2         layer1.1.conv2           (layer1_1_relu,)                       {}\n",
      "call_module    layer1_1_bn2           layer1.1.bn2             (layer1_1_conv2,)                      {}\n",
      "call_function  add_1                  <built-in function add>  (layer1_1_bn2, layer1_0_relu_1)        {}\n",
      "call_module    layer1_1_relu_1        layer1.1.relu            (add_1,)                               {}\n",
      "call_module    layer1_2_conv1         layer1.2.conv1           (layer1_1_relu_1,)                     {}\n",
      "call_module    layer1_2_bn1           layer1.2.bn1             (layer1_2_conv1,)                      {}\n",
      "call_module    layer1_2_relu          layer1.2.relu            (layer1_2_bn1,)                        {}\n",
      "call_module    layer1_2_conv2         layer1.2.conv2           (layer1_2_relu,)                       {}\n",
      "call_module    layer1_2_bn2           layer1.2.bn2             (layer1_2_conv2,)                      {}\n",
      "call_function  add_2                  <built-in function add>  (layer1_2_bn2, layer1_1_relu_1)        {}\n",
      "call_module    layer1_2_relu_1        layer1.2.relu            (add_2,)                               {}\n",
      "call_module    layer2_0_conv1         layer2.0.conv1           (layer1_2_relu_1,)                     {}\n",
      "call_module    layer2_0_bn1           layer2.0.bn1             (layer2_0_conv1,)                      {}\n",
      "call_module    layer2_0_relu          layer2.0.relu            (layer2_0_bn1,)                        {}\n",
      "call_module    layer2_0_conv2         layer2.0.conv2           (layer2_0_relu,)                       {}\n",
      "call_module    layer2_0_bn2           layer2.0.bn2             (layer2_0_conv2,)                      {}\n",
      "call_module    layer2_0_downsample_0  layer2.0.downsample.0    (layer1_2_relu_1,)                     {}\n",
      "call_module    layer2_0_downsample_1  layer2.0.downsample.1    (layer2_0_downsample_0,)               {}\n",
      "call_function  add_3                  <built-in function add>  (layer2_0_bn2, layer2_0_downsample_1)  {}\n",
      "call_module    layer2_0_relu_1        layer2.0.relu            (add_3,)                               {}\n",
      "call_module    layer2_1_conv1         layer2.1.conv1           (layer2_0_relu_1,)                     {}\n",
      "call_module    layer2_1_bn1           layer2.1.bn1             (layer2_1_conv1,)                      {}\n",
      "call_module    layer2_1_relu          layer2.1.relu            (layer2_1_bn1,)                        {}\n",
      "call_module    layer2_1_conv2         layer2.1.conv2           (layer2_1_relu,)                       {}\n",
      "call_module    layer2_1_bn2           layer2.1.bn2             (layer2_1_conv2,)                      {}\n",
      "call_function  add_4                  <built-in function add>  (layer2_1_bn2, layer2_0_relu_1)        {}\n",
      "call_module    layer2_1_relu_1        layer2.1.relu            (add_4,)                               {}\n",
      "call_module    layer2_2_conv1         layer2.2.conv1           (layer2_1_relu_1,)                     {}\n",
      "call_module    layer2_2_bn1           layer2.2.bn1             (layer2_2_conv1,)                      {}\n",
      "call_module    layer2_2_relu          layer2.2.relu            (layer2_2_bn1,)                        {}\n",
      "call_module    layer2_2_conv2         layer2.2.conv2           (layer2_2_relu,)                       {}\n",
      "call_module    layer2_2_bn2           layer2.2.bn2             (layer2_2_conv2,)                      {}\n",
      "call_function  add_5                  <built-in function add>  (layer2_2_bn2, layer2_1_relu_1)        {}\n",
      "call_module    layer2_2_relu_1        layer2.2.relu            (add_5,)                               {}\n",
      "call_module    layer3_0_conv1         layer3.0.conv1           (layer2_2_relu_1,)                     {}\n",
      "call_module    layer3_0_bn1           layer3.0.bn1             (layer3_0_conv1,)                      {}\n",
      "call_module    layer3_0_relu          layer3.0.relu            (layer3_0_bn1,)                        {}\n",
      "call_module    layer3_0_conv2         layer3.0.conv2           (layer3_0_relu,)                       {}\n",
      "call_module    layer3_0_bn2           layer3.0.bn2             (layer3_0_conv2,)                      {}\n",
      "call_module    layer3_0_downsample_0  layer3.0.downsample.0    (layer2_2_relu_1,)                     {}\n",
      "call_module    layer3_0_downsample_1  layer3.0.downsample.1    (layer3_0_downsample_0,)               {}\n",
      "call_function  add_6                  <built-in function add>  (layer3_0_bn2, layer3_0_downsample_1)  {}\n",
      "call_module    layer3_0_relu_1        layer3.0.relu            (add_6,)                               {}\n",
      "call_module    layer3_1_conv1         layer3.1.conv1           (layer3_0_relu_1,)                     {}\n",
      "call_module    layer3_1_bn1           layer3.1.bn1             (layer3_1_conv1,)                      {}\n",
      "call_module    layer3_1_relu          layer3.1.relu            (layer3_1_bn1,)                        {}\n",
      "call_module    layer3_1_conv2         layer3.1.conv2           (layer3_1_relu,)                       {}\n",
      "call_module    layer3_1_bn2           layer3.1.bn2             (layer3_1_conv2,)                      {}\n",
      "call_function  add_7                  <built-in function add>  (layer3_1_bn2, layer3_0_relu_1)        {}\n",
      "call_module    layer3_1_relu_1        layer3.1.relu            (add_7,)                               {}\n",
      "call_module    layer3_2_conv1         layer3.2.conv1           (layer3_1_relu_1,)                     {}\n",
      "call_module    layer3_2_bn1           layer3.2.bn1             (layer3_2_conv1,)                      {}\n",
      "call_module    layer3_2_relu          layer3.2.relu            (layer3_2_bn1,)                        {}\n",
      "call_module    layer3_2_conv2         layer3.2.conv2           (layer3_2_relu,)                       {}\n",
      "call_module    layer3_2_bn2           layer3.2.bn2             (layer3_2_conv2,)                      {}\n",
      "call_function  add_8                  <built-in function add>  (layer3_2_bn2, layer3_1_relu_1)        {}\n",
      "call_module    layer3_2_relu_1        layer3.2.relu            (add_8,)                               {}\n",
      "call_module    avgpool                avgpool                  (layer3_2_relu_1,)                     {}\n",
      "call_module    flatten                flatten                  (avgpool,)                             {}\n",
      "call_module    fc                     fc                       (flatten,)                             {}\n",
      "output         output                 output                   (fc,)                                  {}\n",
      "opcode       name                   target                 args                                     kwargs\n",
      "-----------  ---------------------  ---------------------  ---------------------------------------  --------\n",
      "placeholder  x                      x                      ()                                       {}\n",
      "call_module  conv1_1                conv1                  (x,)                                     {}\n",
      "call_module  bn1_1                  bn1                    (conv1_1,)                               {}\n",
      "call_module  relu_1                 relu                   (bn1_1,)                                 {}\n",
      "call_module  layer1_0_conv1_1       layer1_0_conv1         (relu_1,)                                {}\n",
      "call_module  layer1_0_bn1_1         layer1_0_bn1           (layer1_0_conv1_1,)                      {}\n",
      "call_module  layer1_0_relu_2        layer1_0_relu          (layer1_0_bn1_1,)                        {}\n",
      "call_module  layer1_0_conv2_1       layer1_0_conv2         (layer1_0_relu_2,)                       {}\n",
      "call_module  layer1_0_bn2_1         layer1_0_bn2           (layer1_0_conv2_1,)                      {}\n",
      "call_module  add_9                  add                    (layer1_0_bn2_1, relu_1)                 {}\n",
      "call_module  layer1_0_relu_3        layer1_0_relu_1        (add_9,)                                 {}\n",
      "call_module  layer1_1_conv1_1       layer1_1_conv1         (layer1_0_relu_3,)                       {}\n",
      "call_module  layer1_1_bn1_1         layer1_1_bn1           (layer1_1_conv1_1,)                      {}\n",
      "call_module  layer1_1_relu_2        layer1_1_relu          (layer1_1_bn1_1,)                        {}\n",
      "call_module  layer1_1_conv2_1       layer1_1_conv2         (layer1_1_relu_2,)                       {}\n",
      "call_module  layer1_1_bn2_1         layer1_1_bn2           (layer1_1_conv2_1,)                      {}\n",
      "call_module  add_10                 add_1                  (layer1_1_bn2_1, layer1_0_relu_3)        {}\n",
      "call_module  layer1_1_relu_3        layer1_1_relu_1        (add_10,)                                {}\n",
      "call_module  layer1_2_conv1_1       layer1_2_conv1         (layer1_1_relu_3,)                       {}\n",
      "call_module  layer1_2_bn1_1         layer1_2_bn1           (layer1_2_conv1_1,)                      {}\n",
      "call_module  layer1_2_relu_2        layer1_2_relu          (layer1_2_bn1_1,)                        {}\n",
      "call_module  layer1_2_conv2_1       layer1_2_conv2         (layer1_2_relu_2,)                       {}\n",
      "call_module  layer1_2_bn2_1         layer1_2_bn2           (layer1_2_conv2_1,)                      {}\n",
      "call_module  add_11                 add_2                  (layer1_2_bn2_1, layer1_1_relu_3)        {}\n",
      "call_module  layer1_2_relu_3        layer1_2_relu_1        (add_11,)                                {}\n",
      "call_module  layer2_0_conv1_1       layer2_0_conv1         (layer1_2_relu_3,)                       {}\n",
      "call_module  layer2_0_bn1_1         layer2_0_bn1           (layer2_0_conv1_1,)                      {}\n",
      "call_module  layer2_0_relu_2        layer2_0_relu          (layer2_0_bn1_1,)                        {}\n",
      "call_module  layer2_0_conv2_1       layer2_0_conv2         (layer2_0_relu_2,)                       {}\n",
      "call_module  layer2_0_bn2_1         layer2_0_bn2           (layer2_0_conv2_1,)                      {}\n",
      "call_module  layer2_0_downsample_2  layer2_0_downsample_0  (layer1_2_relu_3,)                       {}\n",
      "call_module  layer2_0_downsample_3  layer2_0_downsample_1  (layer2_0_downsample_2,)                 {}\n",
      "call_module  add_12                 add_3                  (layer2_0_bn2_1, layer2_0_downsample_3)  {}\n",
      "call_module  layer2_0_relu_3        layer2_0_relu_1        (add_12,)                                {}\n",
      "call_module  layer2_1_conv1_1       layer2_1_conv1         (layer2_0_relu_3,)                       {}\n",
      "call_module  layer2_1_bn1_1         layer2_1_bn1           (layer2_1_conv1_1,)                      {}\n",
      "call_module  layer2_1_relu_2        layer2_1_relu          (layer2_1_bn1_1,)                        {}\n",
      "call_module  layer2_1_conv2_1       layer2_1_conv2         (layer2_1_relu_2,)                       {}\n",
      "call_module  layer2_1_bn2_1         layer2_1_bn2           (layer2_1_conv2_1,)                      {}\n",
      "call_module  add_13                 add_4                  (layer2_1_bn2_1, layer2_0_relu_3)        {}\n",
      "call_module  layer2_1_relu_3        layer2_1_relu_1        (add_13,)                                {}\n",
      "call_module  layer2_2_conv1_1       layer2_2_conv1         (layer2_1_relu_3,)                       {}\n",
      "call_module  layer2_2_bn1_1         layer2_2_bn1           (layer2_2_conv1_1,)                      {}\n",
      "call_module  layer2_2_relu_2        layer2_2_relu          (layer2_2_bn1_1,)                        {}\n",
      "call_module  layer2_2_conv2_1       layer2_2_conv2         (layer2_2_relu_2,)                       {}\n",
      "call_module  layer2_2_bn2_1         layer2_2_bn2           (layer2_2_conv2_1,)                      {}\n",
      "call_module  add_14                 add_5                  (layer2_2_bn2_1, layer2_1_relu_3)        {}\n",
      "call_module  layer2_2_relu_3        layer2_2_relu_1        (add_14,)                                {}\n",
      "call_module  layer3_0_conv1_1       layer3_0_conv1         (layer2_2_relu_3,)                       {}\n",
      "call_module  layer3_0_bn1_1         layer3_0_bn1           (layer3_0_conv1_1,)                      {}\n",
      "call_module  layer3_0_relu_2        layer3_0_relu          (layer3_0_bn1_1,)                        {}\n",
      "call_module  layer3_0_conv2_1       layer3_0_conv2         (layer3_0_relu_2,)                       {}\n",
      "call_module  layer3_0_bn2_1         layer3_0_bn2           (layer3_0_conv2_1,)                      {}\n",
      "call_module  layer3_0_downsample_2  layer3_0_downsample_0  (layer2_2_relu_3,)                       {}\n",
      "call_module  layer3_0_downsample_3  layer3_0_downsample_1  (layer3_0_downsample_2,)                 {}\n",
      "call_module  add_15                 add_6                  (layer3_0_bn2_1, layer3_0_downsample_3)  {}\n",
      "call_module  layer3_0_relu_3        layer3_0_relu_1        (add_15,)                                {}\n",
      "call_module  layer3_1_conv1_1       layer3_1_conv1         (layer3_0_relu_3,)                       {}\n",
      "call_module  layer3_1_bn1_1         layer3_1_bn1           (layer3_1_conv1_1,)                      {}\n",
      "call_module  layer3_1_relu_2        layer3_1_relu          (layer3_1_bn1_1,)                        {}\n",
      "call_module  layer3_1_conv2_1       layer3_1_conv2         (layer3_1_relu_2,)                       {}\n",
      "call_module  layer3_1_bn2_1         layer3_1_bn2           (layer3_1_conv2_1,)                      {}\n",
      "call_module  add_16                 add_7                  (layer3_1_bn2_1, layer3_0_relu_3)        {}\n",
      "call_module  layer3_1_relu_3        layer3_1_relu_1        (add_16,)                                {}\n",
      "call_module  layer3_2_conv1_1       layer3_2_conv1         (layer3_1_relu_3,)                       {}\n",
      "call_module  layer3_2_bn1_1         layer3_2_bn1           (layer3_2_conv1_1,)                      {}\n",
      "call_module  layer3_2_relu_2        layer3_2_relu          (layer3_2_bn1_1,)                        {}\n",
      "call_module  layer3_2_conv2_1       layer3_2_conv2         (layer3_2_relu_2,)                       {}\n",
      "call_module  layer3_2_bn2_1         layer3_2_bn2           (layer3_2_conv2_1,)                      {}\n",
      "call_module  add_17                 add_8                  (layer3_2_bn2_1, layer3_1_relu_3)        {}\n",
      "call_module  layer3_2_relu_3        layer3_2_relu_1        (add_17,)                                {}\n",
      "call_module  avgpool_1              avgpool                (layer3_2_relu_3,)                       {}\n",
      "call_module  flatten_1              flatten                (avgpool_1,)                             {}\n",
      "call_module  fc_1                   fc                     (flatten_1,)                             {}\n",
      "output       output                 output                 (fc_1,)                                  {}\n"
     ]
    }
   ],
   "source": [
    "model = QuantModel(model, qconfig).cuda()    #将model转化为量化模型，以支持后续QAT的各种量化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Define loss function, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[100, 150], last_epoch=start_epoch - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. QAT\n",
    "## 2.1 Calibration\n",
    "通过calibration统计参数范围，初步确定量化scale和zeropoint（后续QAT训练时还会调整），目前使用256张输入图像来统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): QConv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0476, 0.0933], zp=[0.0, 0.0]\n",
      "  (bn1): QBatchNorm2d fake_fused: True\n",
      "  (relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_0_conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0592, 0.0776], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.1386, zp=0.0000\n",
      "  (layer1_0_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer1_0_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_0_conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0631, 0.0814], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.1176, zp=0.0000\n",
      "  (layer1_0_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add): QAddfake_fused: True\n",
      "  (layer1_0_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_1_conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0654, 0.0766], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2276, zp=0.0000\n",
      "  (layer1_1_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer1_1_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_1_conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0629, 0.0809], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.0859, zp=0.0000\n",
      "  (layer1_1_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_1): QAddfake_fused: True\n",
      "  (layer1_1_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_2_conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0620, 0.0818], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2985, zp=0.0000\n",
      "  (layer1_2_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer1_2_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_2_conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0680, 0.0804], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2151, zp=0.0000\n",
      "  (layer1_2_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_2): QAddfake_fused: True\n",
      "  (layer1_2_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_0_conv1): QConv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0439, 0.0553], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.3644, zp=0.0000\n",
      "  (layer2_0_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer2_0_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_0_conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0456, 0.0556], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2172, zp=0.0000\n",
      "  (layer2_0_bn2): QBatchNorm2d fake_fused: True\n",
      "  (layer2_0_downsample_0): QConv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0882, 0.1875], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.3644, zp=0.0000\n",
      "  (layer2_0_downsample_1): QBatchNorm2d fake_fused: True\n",
      "  (add_3): QAddfake_fused: True\n",
      "  (layer2_0_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_1_conv1): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0454, 0.0544], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2786, zp=0.0000\n",
      "  (layer2_1_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer2_1_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_1_conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0440, 0.0551], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2935, zp=0.0000\n",
      "  (layer2_1_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_4): QAddfake_fused: True\n",
      "  (layer2_1_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_2_conv1): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0456, 0.0552], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.5013, zp=0.0000\n",
      "  (layer2_2_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer2_2_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_2_conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0471, 0.0550], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2870, zp=0.0000\n",
      "  (layer2_2_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_5): QAddfake_fused: True\n",
      "  (layer2_2_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_0_conv1): QConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0327, 0.0386], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.6891, zp=0.0000\n",
      "  (layer3_0_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer3_0_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_0_conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0332, 0.0381], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.3876, zp=0.0000\n",
      "  (layer3_0_bn2): QBatchNorm2d fake_fused: True\n",
      "  (layer3_0_downsample_0): QConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0706, 0.1469], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.6891, zp=0.0000\n",
      "  (layer3_0_downsample_1): QBatchNorm2d fake_fused: True\n",
      "  (add_6): QAddfake_fused: True\n",
      "  (layer3_0_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_1_conv1): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0330, 0.0399], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.4794, zp=0.0000\n",
      "  (layer3_1_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer3_1_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_1_conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0325, 0.0380], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.4670, zp=0.0000\n",
      "  (layer3_1_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_7): QAddfake_fused: True\n",
      "  (layer3_1_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_2_conv1): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0332, 0.0378], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.8395, zp=0.0000\n",
      "  (layer3_2_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer3_2_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_2_conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0331, 0.0377], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.6792, zp=0.0000\n",
      "  (layer3_2_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_8): QAddfake_fused: True\n",
      "  (layer3_2_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (avgpool): QAdaptiveAvgPool2d(output_size=(1, 1))fake_fused: False\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=1.0699, zp=0.0000\n",
      "  (flatten): Flatten()\n",
      "  (fc): QLinear(in_features=64, out_features=10, bias=True)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int8\t qmin: -128  qmax: 127, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0412, 0.0544], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=1.0699, zp=0.0000\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1_1 = self.conv1(x);  x = None\n",
      "    bn1_1 = self.bn1(conv1_1);  conv1_1 = None\n",
      "    relu_1 = self.relu(bn1_1);  bn1_1 = None\n",
      "    layer1_0_conv1_1 = self.layer1_0_conv1(relu_1)\n",
      "    layer1_0_bn1_1 = self.layer1_0_bn1(layer1_0_conv1_1);  layer1_0_conv1_1 = None\n",
      "    layer1_0_relu_2 = self.layer1_0_relu(layer1_0_bn1_1);  layer1_0_bn1_1 = None\n",
      "    layer1_0_conv2_1 = self.layer1_0_conv2(layer1_0_relu_2);  layer1_0_relu_2 = None\n",
      "    layer1_0_bn2_1 = self.layer1_0_bn2(layer1_0_conv2_1);  layer1_0_conv2_1 = None\n",
      "    add_9 = self.add(layer1_0_bn2_1, relu_1);  layer1_0_bn2_1 = relu_1 = None\n",
      "    layer1_0_relu_3 = self.layer1_0_relu_1(add_9);  add_9 = None\n",
      "    layer1_1_conv1_1 = self.layer1_1_conv1(layer1_0_relu_3)\n",
      "    layer1_1_bn1_1 = self.layer1_1_bn1(layer1_1_conv1_1);  layer1_1_conv1_1 = None\n",
      "    layer1_1_relu_2 = self.layer1_1_relu(layer1_1_bn1_1);  layer1_1_bn1_1 = None\n",
      "    layer1_1_conv2_1 = self.layer1_1_conv2(layer1_1_relu_2);  layer1_1_relu_2 = None\n",
      "    layer1_1_bn2_1 = self.layer1_1_bn2(layer1_1_conv2_1);  layer1_1_conv2_1 = None\n",
      "    add_10 = self.add_1(layer1_1_bn2_1, layer1_0_relu_3);  layer1_1_bn2_1 = layer1_0_relu_3 = None\n",
      "    layer1_1_relu_3 = self.layer1_1_relu_1(add_10);  add_10 = None\n",
      "    layer1_2_conv1_1 = self.layer1_2_conv1(layer1_1_relu_3)\n",
      "    layer1_2_bn1_1 = self.layer1_2_bn1(layer1_2_conv1_1);  layer1_2_conv1_1 = None\n",
      "    layer1_2_relu_2 = self.layer1_2_relu(layer1_2_bn1_1);  layer1_2_bn1_1 = None\n",
      "    layer1_2_conv2_1 = self.layer1_2_conv2(layer1_2_relu_2);  layer1_2_relu_2 = None\n",
      "    layer1_2_bn2_1 = self.layer1_2_bn2(layer1_2_conv2_1);  layer1_2_conv2_1 = None\n",
      "    add_11 = self.add_2(layer1_2_bn2_1, layer1_1_relu_3);  layer1_2_bn2_1 = layer1_1_relu_3 = None\n",
      "    layer1_2_relu_3 = self.layer1_2_relu_1(add_11);  add_11 = None\n",
      "    layer2_0_conv1_1 = self.layer2_0_conv1(layer1_2_relu_3)\n",
      "    layer2_0_bn1_1 = self.layer2_0_bn1(layer2_0_conv1_1);  layer2_0_conv1_1 = None\n",
      "    layer2_0_relu_2 = self.layer2_0_relu(layer2_0_bn1_1);  layer2_0_bn1_1 = None\n",
      "    layer2_0_conv2_1 = self.layer2_0_conv2(layer2_0_relu_2);  layer2_0_relu_2 = None\n",
      "    layer2_0_bn2_1 = self.layer2_0_bn2(layer2_0_conv2_1);  layer2_0_conv2_1 = None\n",
      "    layer2_0_downsample_2 = self.layer2_0_downsample_0(layer1_2_relu_3);  layer1_2_relu_3 = None\n",
      "    layer2_0_downsample_3 = self.layer2_0_downsample_1(layer2_0_downsample_2);  layer2_0_downsample_2 = None\n",
      "    add_12 = self.add_3(layer2_0_bn2_1, layer2_0_downsample_3);  layer2_0_bn2_1 = layer2_0_downsample_3 = None\n",
      "    layer2_0_relu_3 = self.layer2_0_relu_1(add_12);  add_12 = None\n",
      "    layer2_1_conv1_1 = self.layer2_1_conv1(layer2_0_relu_3)\n",
      "    layer2_1_bn1_1 = self.layer2_1_bn1(layer2_1_conv1_1);  layer2_1_conv1_1 = None\n",
      "    layer2_1_relu_2 = self.layer2_1_relu(layer2_1_bn1_1);  layer2_1_bn1_1 = None\n",
      "    layer2_1_conv2_1 = self.layer2_1_conv2(layer2_1_relu_2);  layer2_1_relu_2 = None\n",
      "    layer2_1_bn2_1 = self.layer2_1_bn2(layer2_1_conv2_1);  layer2_1_conv2_1 = None\n",
      "    add_13 = self.add_4(layer2_1_bn2_1, layer2_0_relu_3);  layer2_1_bn2_1 = layer2_0_relu_3 = None\n",
      "    layer2_1_relu_3 = self.layer2_1_relu_1(add_13);  add_13 = None\n",
      "    layer2_2_conv1_1 = self.layer2_2_conv1(layer2_1_relu_3)\n",
      "    layer2_2_bn1_1 = self.layer2_2_bn1(layer2_2_conv1_1);  layer2_2_conv1_1 = None\n",
      "    layer2_2_relu_2 = self.layer2_2_relu(layer2_2_bn1_1);  layer2_2_bn1_1 = None\n",
      "    layer2_2_conv2_1 = self.layer2_2_conv2(layer2_2_relu_2);  layer2_2_relu_2 = None\n",
      "    layer2_2_bn2_1 = self.layer2_2_bn2(layer2_2_conv2_1);  layer2_2_conv2_1 = None\n",
      "    add_14 = self.add_5(layer2_2_bn2_1, layer2_1_relu_3);  layer2_2_bn2_1 = layer2_1_relu_3 = None\n",
      "    layer2_2_relu_3 = self.layer2_2_relu_1(add_14);  add_14 = None\n",
      "    layer3_0_conv1_1 = self.layer3_0_conv1(layer2_2_relu_3)\n",
      "    layer3_0_bn1_1 = self.layer3_0_bn1(layer3_0_conv1_1);  layer3_0_conv1_1 = None\n",
      "    layer3_0_relu_2 = self.layer3_0_relu(layer3_0_bn1_1);  layer3_0_bn1_1 = None\n",
      "    layer3_0_conv2_1 = self.layer3_0_conv2(layer3_0_relu_2);  layer3_0_relu_2 = None\n",
      "    layer3_0_bn2_1 = self.layer3_0_bn2(layer3_0_conv2_1);  layer3_0_conv2_1 = None\n",
      "    layer3_0_downsample_2 = self.layer3_0_downsample_0(layer2_2_relu_3);  layer2_2_relu_3 = None\n",
      "    layer3_0_downsample_3 = self.layer3_0_downsample_1(layer3_0_downsample_2);  layer3_0_downsample_2 = None\n",
      "    add_15 = self.add_6(layer3_0_bn2_1, layer3_0_downsample_3);  layer3_0_bn2_1 = layer3_0_downsample_3 = None\n",
      "    layer3_0_relu_3 = self.layer3_0_relu_1(add_15);  add_15 = None\n",
      "    layer3_1_conv1_1 = self.layer3_1_conv1(layer3_0_relu_3)\n",
      "    layer3_1_bn1_1 = self.layer3_1_bn1(layer3_1_conv1_1);  layer3_1_conv1_1 = None\n",
      "    layer3_1_relu_2 = self.layer3_1_relu(layer3_1_bn1_1);  layer3_1_bn1_1 = None\n",
      "    layer3_1_conv2_1 = self.layer3_1_conv2(layer3_1_relu_2);  layer3_1_relu_2 = None\n",
      "    layer3_1_bn2_1 = self.layer3_1_bn2(layer3_1_conv2_1);  layer3_1_conv2_1 = None\n",
      "    add_16 = self.add_7(layer3_1_bn2_1, layer3_0_relu_3);  layer3_1_bn2_1 = layer3_0_relu_3 = None\n",
      "    layer3_1_relu_3 = self.layer3_1_relu_1(add_16);  add_16 = None\n",
      "    layer3_2_conv1_1 = self.layer3_2_conv1(layer3_1_relu_3)\n",
      "    layer3_2_bn1_1 = self.layer3_2_bn1(layer3_2_conv1_1);  layer3_2_conv1_1 = None\n",
      "    layer3_2_relu_2 = self.layer3_2_relu(layer3_2_bn1_1);  layer3_2_bn1_1 = None\n",
      "    layer3_2_conv2_1 = self.layer3_2_conv2(layer3_2_relu_2);  layer3_2_relu_2 = None\n",
      "    layer3_2_bn2_1 = self.layer3_2_bn2(layer3_2_conv2_1);  layer3_2_conv2_1 = None\n",
      "    add_17 = self.add_8(layer3_2_bn2_1, layer3_1_relu_3);  layer3_2_bn2_1 = layer3_1_relu_3 = None\n",
      "    layer3_2_relu_3 = self.layer3_2_relu_1(add_17);  add_17 = None\n",
      "    avgpool_1 = self.avgpool(layer3_2_relu_3);  layer3_2_relu_3 = None\n",
      "    flatten_1 = self.flatten(avgpool_1);  avgpool_1 = None\n",
      "    fc_1 = self.fc(flatten_1);  flatten_1 = None\n",
      "    return fc_1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model.prepare_calibration()    #进入calibration状态\n",
    "calib_size, cur_size = 256, 0\n",
    "#在eval模式且无需计算梯度的条件下用训练集进行calibrate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in trainloader:\n",
    "        model(data.cuda())\n",
    "        cur_size += data.shape[0]\n",
    "        if cur_size >= calib_size:\n",
    "            break\n",
    "model.init_QAT()    #调用API，初始化QAT\n",
    "model.set_lastmodule_wbit(bit=8)    #额外规定最后一层权重的量化bit数\n",
    "print(model.model)    #可以在print出的模型信息中看到网络各层weight和activation的量化scale和zeropoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Function\n",
    "训练模型，与原模型的训练代码完全相同，fake quantize等过程在QuantModel中自行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
    "    data_time = AverageMeter(\"Data\", \":6.3f\")\n",
    "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
    "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch),\n",
    "    )\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = accuracy(output, target, topk=(1,))[0]\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Validation Function\n",
    "验证部分代码也与原模型完全一致，量化在QuantModel中自行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter(\"Time\", \":6.3f\", Summary.NONE)\n",
    "    losses = AverageMeter(\"Loss\", \":.4e\", Summary.NONE)\n",
    "    top1 = AverageMeter(\"Acc@1\", \":6.2f\", Summary.AVERAGE)\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader), [batch_time, losses, top1], prefix=\"Test: \"\n",
    "    )\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        start = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1 = accuracy(output, target, topk=(1,))[0]\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        progress.display_summary()\n",
    "\n",
    "    print(\"Total Time: {}\".format(time.time() - start))\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Tool Functions\n",
    "一些辅助性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, \"model_best.pth.tar\")\n",
    "\n",
    "class Summary(Enum):\n",
    "    NONE = 0\n",
    "    AVERAGE = 1\n",
    "    SUM = 2\n",
    "    COUNT = 3\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=\":f\", summary_type=Summary.AVERAGE):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.summary_type = summary_type\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "    def summary(self):\n",
    "        fmtstr = \"\"\n",
    "        if self.summary_type is Summary.NONE:\n",
    "            fmtstr = \"\"\n",
    "        elif self.summary_type is Summary.AVERAGE:\n",
    "            fmtstr = \"{name} {avg:.3f}\"\n",
    "        elif self.summary_type is Summary.SUM:\n",
    "            fmtstr = \"{name} {sum:.3f}\"\n",
    "        elif self.summary_type is Summary.COUNT:\n",
    "            fmtstr = \"{name} {count:.3f}\"\n",
    "        else:\n",
    "            raise ValueError(\"invalid summary type %r\" % self.summary_type)\n",
    "\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print(\"\\t\".join(entries))\n",
    "\n",
    "    def display_summary(self):\n",
    "        entries = [\" *\"]\n",
    "        entries += [meter.summary() for meter in self.meters]\n",
    "        print(\" \".join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = \"{:\" + str(num_digits) + \"d}\"\n",
    "        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Train and Validate\n",
    "QAT训练，并在每个epoch后进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # train for one epoch\n",
    "    train(trainloader, model, criterion, optimizer, epoch,)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(testloader, model, criterion)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    save_checkpoint(\n",
    "       {\n",
    "           \"epoch\": epoch + 1,\n",
    "           \"state_dict\": model.state_dict(),\n",
    "           \"best_acc1\": best_acc1,\n",
    "           \"optimizer\": optimizer.state_dict(),\n",
    "           \"scheduler\": scheduler.state_dict(),\n",
    "       },\n",
    "       is_best,\n",
    "     )\n",
    "\n",
    "print(\"Training is Done, best: {}\".format(best_acc1))\n",
    "\n",
    "# export onnx\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model.export_onnx(torch.randn(1, 3, 32,32), name=\"qresnet20.onnx\",extra_info=True)\n",
    "\n",
    "from IPython import embed\n",
    "embed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf3a63ab5f9f4019e467b64c02ed82b4d340692322a673bf824db751f55183b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
